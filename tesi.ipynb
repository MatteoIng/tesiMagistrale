{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9602529  0.07039406]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_274126/236641631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscrete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/spaces/space.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, mask)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mA\u001b[0m \u001b[0msampled\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gymnasium.spaces import Discrete, Dict, Box,Space\n",
    "print(Box(low=0,high=1,shape=(2,)).sample())\n",
    "print(Space((2,),dtype=list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 09:24:28,986\tINFO worker.py:1633 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-09-25 09:24:30,429\tWARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-09-25 09:24:30,429\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='MyEnv', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('MyEnv').build()` instead. This will raise an error in the future!\n",
      "/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/matteo/.local/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/matteo/.local/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/matteo/.local/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[2m\u001b[36m(pid=319838)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "2023-09-25 09:24:35,359\tERROR actor_manager.py:500 -- Ray error, taking actor 1 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319837, ip=10.25.252.249, actor_id=95915dfcc79166651d162b4401000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f950d9678b0>)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 741, in make\n",
      "    env_spec = _find_spec(id)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 527, in _find_spec\n",
      "    _check_version_exists(ns, name, version)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 393, in _check_version_exists\n",
      "    _check_name_exists(ns, name)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 370, in _check_name_exists\n",
      "    raise error.NameNotFound(\n",
      "gymnasium.error.NameNotFound: Environment `MyEnv` doesn't exist.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319837, ip=10.25.252.249, actor_id=95915dfcc79166651d162b4401000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f950d9678b0>)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 397, in __init__\n",
      "    self.env = env_creator(copy.deepcopy(self.env_context))\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/env/utils.py\", line 169, in _gym_env_creator\n",
      "    raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\n",
      "ray.rllib.utils.error.EnvError: The env string you provided ('MyEnv') is:\n",
      "a) Not a supported/installed environment.\n",
      "b) Not a tune-registered environment creator.\n",
      "c) Not a valid env class string.\n",
      "\n",
      "Try one of the following:\n",
      "a) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n",
      "   For VizDoom support: Install VizDoom\n",
      "   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n",
      "   `pip install vizdoomgym`.\n",
      "   For PyBullet support: `pip install pybullet`.\n",
      "b) To register your custom env, do `from ray import tune;\n",
      "   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n",
      "   Then in your config, do `config['env'] = [name]`.\n",
      "c) Make sure you provide a fully qualified classpath, e.g.:\n",
      "   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n",
      "2023-09-25 09:24:35,360\tERROR actor_manager.py:500 -- Ray error, taking actor 2 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319838, ip=10.25.252.249, actor_id=4e38ca30047a832cb551afe701000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f10590db910>)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 741, in make\n",
      "    env_spec = _find_spec(id)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 527, in _find_spec\n",
      "    _check_version_exists(ns, name, version)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 393, in _check_version_exists\n",
      "    _check_name_exists(ns, name)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 370, in _check_name_exists\n",
      "    raise error.NameNotFound(\n",
      "gymnasium.error.NameNotFound: Environment `MyEnv` doesn't exist.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319838, ip=10.25.252.249, actor_id=4e38ca30047a832cb551afe701000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f10590db910>)\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 397, in __init__\n",
      "    self.env = env_creator(copy.deepcopy(self.env_context))\n",
      "  File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/env/utils.py\", line 169, in _gym_env_creator\n",
      "    raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\n",
      "ray.rllib.utils.error.EnvError: The env string you provided ('MyEnv') is:\n",
      "a) Not a supported/installed environment.\n",
      "b) Not a tune-registered environment creator.\n",
      "c) Not a valid env class string.\n",
      "\n",
      "Try one of the following:\n",
      "a) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n",
      "   For VizDoom support: Install VizDoom\n",
      "   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n",
      "   `pip install vizdoomgym`.\n",
      "   For PyBullet support: `pip install pybullet`.\n",
      "b) To register your custom env, do `from ray import tune;\n",
      "   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n",
      "   Then in your config, do `config['env'] = [name]`.\n",
      "c) Make sure you provide a fully qualified classpath, e.g.:\n",
      "   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319838, ip=10.25.252.249, actor_id=4e38ca30047a832cb551afe701000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f10590db910>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 741, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m     env_spec = _find_spec(id)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 527, in _find_spec\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m     _check_version_exists(ns, name, version)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 393, in _check_version_exists\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m     _check_name_exists(ns, name)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 370, in _check_name_exists\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m     raise error.NameNotFound(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m gymnasium.error.NameNotFound: Environment `MyEnv` doesn't exist.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319838, ip=10.25.252.249, actor_id=4e38ca30047a832cb551afe701000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f10590db910>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 397, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m     self.env = env_creator(copy.deepcopy(self.env_context))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/env/utils.py\", line 169, in _gym_env_creator\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m     raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m ray.rllib.utils.error.EnvError: The env string you provided ('MyEnv') is:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m a) Not a supported/installed environment.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m b) Not a tune-registered environment creator.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m c) Not a valid env class string.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m Try one of the following:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m a) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m    For VizDoom support: Install VizDoom\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m    (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m    `pip install vizdoomgym`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m    For PyBullet support: `pip install pybullet`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m b) To register your custom env, do `from ray import tune;\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m    tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m    Then in your config, do `config['env'] = [name]`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m c) Make sure you provide a fully qualified classpath, e.g.:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319838)\u001b[0m    `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n"
     ]
    },
    {
     "ename": "EnvError",
     "evalue": "The env string you provided ('MyEnv') is:\na) Not a supported/installed environment.\nb) Not a tune-registered environment creator.\nc) Not a valid env class string.\n\nTry one of the following:\na) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n   For VizDoom support: Install VizDoom\n   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n   `pip install vizdoomgym`.\n   For PyBullet support: `pip install pybullet`.\nb) To register your custom env, do `from ray import tune;\n   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n   Then in your config, do `config['env'] = [name]`.\nc) Make sure you provide a fully qualified classpath, e.g.:\n   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 self._setup(\n\u001b[0m\u001b[1;32m    158\u001b[0m                     \u001b[0mvalidate_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Create a number of @ray.remote workers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         self.add_workers(\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36madd_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\u001b[0m in \u001b[0;36m__fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                 \u001b[0mremote_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResultOrError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2548\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayActorError\u001b[0m: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319837, ip=10.25.252.249, actor_id=95915dfcc79166651d162b4401000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f950d9678b0>)\n  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 741, in make\n    env_spec = _find_spec(id)\n  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 527, in _find_spec\n    _check_version_exists(ns, name, version)\n  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 393, in _check_version_exists\n    _check_name_exists(ns, name)\n  File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 370, in _check_name_exists\n    raise error.NameNotFound(\ngymnasium.error.NameNotFound: Environment `MyEnv` doesn't exist.\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319837, ip=10.25.252.249, actor_id=95915dfcc79166651d162b4401000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f950d9678b0>)\n  File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 397, in __init__\n    self.env = env_creator(copy.deepcopy(self.env_context))\n  File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/env/utils.py\", line 169, in _gym_env_creator\n    raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\nray.rllib.utils.error.EnvError: The env string you provided ('MyEnv') is:\na) Not a supported/installed environment.\nb) Not a tune-registered environment creator.\nc) Not a valid env class string.\n\nTry one of the following:\na) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n   For VizDoom support: Install VizDoom\n   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n   `pip install vizdoomgym`.\n   For PyBullet support: `pip install pybullet`.\nb) To register your custom env, do `from ray import tune;\n   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n   Then in your config, do `config['env'] = [name]`.\nc) Make sure you provide a fully qualified classpath, e.g.:\n   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEnvError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_274126/3860809897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m algo = ppo.PPO(env=\"MyEnv\", config={\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;34m\"env_config\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# config to pass to env class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m })\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m         }\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mlogger_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, sync_config, storage)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"StorageContext on the TRAINABLE:\\n{storage}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0msetup_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msetup_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mSETUP_TIME_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;31m# Create a set of env runner actors via a WorkerSet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             self.workers = WorkerSet(\n\u001b[0m\u001b[1;32m    640\u001b[0m                 \u001b[0menv_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mvalidate_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;31m# - e.args[0].args[2]: The original Exception (e.g. a ValueError due\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;31m# to a config mismatch) thrown inside the actor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# In any other case, raise the RayActorError as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEnvError\u001b[0m: The env string you provided ('MyEnv') is:\na) Not a supported/installed environment.\nb) Not a tune-registered environment creator.\nc) Not a valid env class string.\n\nTry one of the following:\na) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n   For VizDoom support: Install VizDoom\n   (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n   `pip install vizdoomgym`.\n   For PyBullet support: `pip install pybullet`.\nb) To register your custom env, do `from ray import tune;\n   tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n   Then in your config, do `config['env'] = [name]`.\nc) Make sure you provide a fully qualified classpath, e.g.:\n   `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319837, ip=10.25.252.249, actor_id=95915dfcc79166651d162b4401000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f950d9678b0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 741, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m     env_spec = _find_spec(id)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 527, in _find_spec\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m     _check_version_exists(ns, name, version)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 393, in _check_version_exists\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m     _check_name_exists(ns, name)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 370, in _check_name_exists\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m     raise error.NameNotFound(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m gymnasium.error.NameNotFound: Environment `MyEnv` doesn't exist.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=319837, ip=10.25.252.249, actor_id=95915dfcc79166651d162b4401000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f950d9678b0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 397, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m     self.env = env_creator(copy.deepcopy(self.env_context))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m   File \"/home/matteo/.local/lib/python3.10/site-packages/ray/rllib/env/utils.py\", line 169, in _gym_env_creator\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m     raise EnvError(ERR_MSG_INVALID_ENV_DESCRIPTOR.format(env_descriptor))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m ray.rllib.utils.error.EnvError: The env string you provided ('MyEnv') is:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m a) Not a supported/installed environment.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m b) Not a tune-registered environment creator.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m c) Not a valid env class string.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m Try one of the following:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m a) For Atari support: `pip install gym[atari] autorom[accept-rom-license]`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m    For VizDoom support: Install VizDoom\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m    (https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md) and\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m    `pip install vizdoomgym`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m    For PyBullet support: `pip install pybullet`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m b) To register your custom env, do `from ray import tune;\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m    tune.register('[name]', lambda cfg: [return env obj from here using cfg])`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m    Then in your config, do `config['env'] = [name]`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m c) Make sure you provide a fully qualified classpath, e.g.:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=319837)\u001b[0m    `ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv`\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ray\n",
    "from ray.rllib.algorithms import ppo\n",
    "from ray.rllib.env.multi_agent_env import  MultiAgentEnv\n",
    "\n",
    "class MyEnv(MultiAgentEnv):\n",
    "    def __init__(self, env_config):\n",
    "        self.MOVES = ['mossa1', 'mossa2','mossa3']\n",
    "\n",
    "        # Questa è la truncation cosi esce per non girare all'infinito\n",
    "        self.NUM_ITERS = 20\n",
    "\n",
    "        # Mappa che in base all'azione eseguita mi da costo, impatto, ecc dell'azione\n",
    "        self.REWARD_MAP = {\n",
    "            'mossa1': (1, 0, 0),\n",
    "            'mossa2': (2, 0, 0),\n",
    "            'mossa3': (3, 0, 0)\n",
    "        }\n",
    "\n",
    "        # per la funzione di reward\n",
    "        self.wt = 0.5\n",
    "        self.wc = 0.5\n",
    "        self.wi = 0.5\n",
    "        self.tMax = 100\n",
    "        self.cMax = 100\n",
    "        self.possible_agents = ['attaccante','difensore']\n",
    "        self.agent_name_mapping = dict(\n",
    "            zip(self.possible_agents, list(range(len(self.possible_agents))))\n",
    "        )\n",
    "        # per ogni agente mette le azioni ovvero tante quante le mosse\n",
    "        # Discrete lo usa per generare uno random con sample()\n",
    "        self.action_space = {agent: [0,1,2] for agent in self.possible_agents}\n",
    "        self.observation_space = {\n",
    "            agent: dict(\n",
    "                {\n",
    "                    # observation dovrebbe avere i parametri dello stato,\n",
    "                    # è lo spazio e lo stato è dato dalla config dei suoi parametri\n",
    "                    # ho preso 2 dove mossa 1 accende spegne il 1 e mossa due uguale\n",
    "                    # Box mi genera una lista e mi controlla nel limiti low and high \n",
    "                    'observation': [False,False,False],\n",
    "\n",
    "                    # stessa dimensione delle mosse per selezionare mosse non selezionabili\n",
    "                    # 2 mosse\n",
    "                    # Box(low=0,high=1,shape=(2,),dtype=bool)\n",
    "                    #\"action_mask\": [True,True]\n",
    "                }\n",
    "            )\n",
    "            for agent in self.possible_agents\n",
    "        }\n",
    "        \n",
    "    def reset(self, seed, options):\n",
    "        self.agents = self.possible_agents[:]\n",
    "        self.rewards = {agent: 0 for agent in self.agents}\n",
    "        self._cumulative_rewards = {agent: 0 for agent in self.agents}\n",
    "############################################### QUando termina a me ? ###################################################        \n",
    "        self.terminations = {agent: False for agent in self.agents}\n",
    "        self.truncations = {agent: False for agent in self.agents}\n",
    "        self.infos = {agent: {} for agent in self.agents}\n",
    "        #self.state = {agent: NONE for agent in self.agents}\n",
    "        #self.observations = {agent: NONE for agent in self.agents}\n",
    "\n",
    "        # credo serve per arrestare\n",
    "        self.num_moves = 0\n",
    "        \"\"\"\n",
    "        Our agent_selector utility allows easy cyclic stepping through the agents list.\n",
    "        \"\"\"\n",
    "        self._agent_selector = agent_selector(self.agents)\n",
    "        self.agent_selection = self._agent_selector.reset()\n",
    "        return self.observation_space,self.infos\n",
    "    \n",
    "    def step(self, action):\n",
    "        if (\n",
    "            self.terminations[self.agent_selection]\n",
    "            or self.truncations[self.agent_selection]\n",
    "        ):\n",
    "            # handles stepping an agent which is already dead\n",
    "            # accepts a None action for the one agent, and moves the agent_selection to\n",
    "            # the next dead agent,  or if there are no more dead agents, to the next live agent\n",
    "            self._was_dead_step(action)\n",
    "            print('ECCOOOO:',self.agents)\n",
    "            return\n",
    "\n",
    "        agent = self.agent_selection\n",
    "        print('Agente in azione:',agent)\n",
    "\n",
    "        reward = self.REWARD_MAP[self.MOVES[action]]\n",
    "        valReward = -self.wt*(reward[0]/self.tMax)-self.wc*(reward[1]/self.cMax)-self.wi*(1) \n",
    "        #rewardInv = -valReward\n",
    "        print('Reward:',valReward)\n",
    "        if self.agent_selection == 'attaccante':\n",
    "            self.rewards[self.agents[0]], self.rewards[self.agents[1]] = (valReward,0)\n",
    "        else:\n",
    "            self.rewards[self.agents[0]], self.rewards[self.agents[1]] = (0,valReward)\n",
    "        \n",
    "        print('Prima della mossa:',self.observation_space)\n",
    "        if action == 0:\n",
    "            self.observation_space[self.agent_selection]['observation'][action]=True\n",
    "        elif action == 1:\n",
    "            self.observation_space[self.agent_selection]['observation'][0]=True\n",
    "            self.observation_space[self.agent_selection]['observation'][action]=True\n",
    "        elif action == 2:\n",
    "            self.observation_space[self.agent_selection]['observation'][0]=True\n",
    "            self.observation_space[self.agent_selection]['observation'][1]=True\n",
    "            self.observation_space[self.agent_selection]['observation'][action]=True\n",
    "        print('Dopo la mossa:',self.observation_space)\n",
    "        self.num_moves += 1\n",
    "        # The truncations dictionary must be updated for all players.\n",
    "        self.truncations = {\n",
    "            agent: self.num_moves >= self.NUM_ITERS for agent in self.agents\n",
    "        }\n",
    "        # se uno degli agenti è in uno stato di tutti True esce \n",
    "        self.terminations = {\n",
    "            agent: True if all(item == True for item in self.observation_space[agent]['observation']) else False for agent in self.agents\n",
    "        }\n",
    "        print('Deve terminare?',self.terminations)\n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "        # Adds .rewards to ._cumulative_rewards\n",
    "        self._accumulate_rewards()\n",
    "        return self.observation_space,self.rewards,self.terminations,self.truncations,self.infos\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "algo = ppo.PPO(env=\"MyEnv\", config={\n",
    "    \"env_config\": {},  # config to pass to env class\n",
    "})\n",
    "\n",
    "while True:\n",
    "    print(algo.train())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
